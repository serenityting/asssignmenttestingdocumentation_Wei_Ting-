# Description in a paragraph

For new data, it starts with collecting the samples from individual (saliva or blood as the source of genetic data). The collected biological samples are analysed and has its test result recorded in the metadata. The genetic data is then extracted (either DNA or RNA) and exported in documents with genetical coding. Quality control has to be performed to clean the data before performing any analysis.  For existing data, the sequencing data is generated and stored. The raw data storage is in the format of FASTQ files. Next, the data form is converted to aligh reads to reference genome using software such as BWA or Bowtie2. This data file can be cleaned and filtered by trimming and QC check to remove low-quality reads. This process is repeated if the quality threshold is bad and if it is good, the VCF files will be stored. The variant type is detected using tools such as GATK, FreeBayes on whether it is Single Nucleotide Polymorphisms (SNPs), Insertions/Deletions (INDELs), or Structural Variations (SVs). Variant annotation (adding functional and contextual information to genetic variants, while filtering helps narrow down the list of candidate variants to find those most likely to be biologically significant) and filtering is then performed on the exported variant in VCF. It is then to be tested to match with the genetic database and stored once there is matching result. The info is save or can be used for generating result by the researcher. 
